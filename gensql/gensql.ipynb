{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain import LLMChain\n",
    "\n",
    "from gensql.langchain.prompt_layer import PromptLayerCustom\n",
    "from gensql.langchain.prompt import *\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from typing import List\n",
    "from qdrant_client.http import models\n",
    "from langchain.vectorstores import Qdrant\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from underthesea import text_normalize\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "env_path = Path(\".\") / \"/Users/hieunguyen/DATN/.env\"\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "os.environ[\"EMBEDDING_OPENAI_API_KEY\"] = os.environ.get(\"EMBEDDING_OPENAI_API_KEY\")\n",
    "\n",
    "import promptlayer\n",
    "# promptlayer.utils.URL_API_PROMPTLAYER\n",
    "promptlayer.api_key = os.environ.get(\"PROMPTLAYER_API_KEY\")\n",
    "from langchain.embeddings import openai\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "import json"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T05:22:36.292782Z",
     "start_time": "2024-07-12T05:22:36.289463Z"
    }
   },
   "id": "30aa06a52527f70e",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "openai_key = os.environ.get(\"OPENAI_API_KEY\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T05:22:36.858005Z",
     "start_time": "2024-07-12T05:22:36.853283Z"
    }
   },
   "id": "936b21265e831c2e",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class CheckSQL:\n",
    "    def __init__(self, model_name) -> None:\n",
    "        self.model_name = model_name\n",
    "\n",
    "        self.llm = PromptLayerCustom(model_name=self.model_name,\n",
    "                                     openai_api_key=openai_key,\n",
    "                                     temperature=0,\n",
    "                                     max_tokens=512,\n",
    "                                     pl_tags=['filter_check_SQL', 'api-server']\n",
    "                                    )\n",
    "        self.llm_chain = LLMChain(\n",
    "            llm=self.llm,\n",
    "            prompt=CHECKSQL_TEMPLATE\n",
    "        )\n",
    "\n",
    "    async def get_response(self, question, time, SQL, script_tables):\n",
    "        # print(ANALYZER_TEMPLATE.format(question=question, time=time, script_tables=script_tables))\n",
    "        return await self.llm_chain.arun({\"question\": question, \"time\": time, \"SQL\": SQL, \"script_tables\": script_tables})\n",
    "    \n",
    "class GenerateSQL:\n",
    "    def __init__(self, model_name) -> None:\n",
    "        self.model_name = model_name\n",
    "\n",
    "        self.llm = PromptLayerCustom(model_name=self.model_name,\n",
    "                                     openai_api_key=openai_key,\n",
    "                                     temperature=0,\n",
    "                                     max_tokens=512,\n",
    "                                     pl_tags=['filter_generate_SQL', 'api-server']\n",
    "                                    )\n",
    "        self.llm_chain = LLMChain(\n",
    "            llm=self.llm,\n",
    "            prompt=GENERATE_SQL_TEMPLATE\n",
    "        )\n",
    "\n",
    "    async def get_response(self, question, time, script_tables):\n",
    "        # print(COMPANY_INFO_PROMPT.format(context=data, question=question))\n",
    "        return await self.llm_chain.arun({\"question\": question, \"time\": time, \"script_tables\": script_tables})\n",
    "\n",
    "class RepairSQL:\n",
    "    def __init__(self, model_name) -> None:\n",
    "        self.model_name = model_name\n",
    "\n",
    "        self.llm = PromptLayerCustom(model_name=self.model_name,\n",
    "                                     openai_api_key=openai_key,\n",
    "                                     temperature=0,\n",
    "                                     max_tokens=512,\n",
    "                                     pl_tags=['filter_repair_SQL', 'api-server']\n",
    "                                    )\n",
    "        self.llm_chain = LLMChain(\n",
    "            llm=self.llm,\n",
    "            prompt=REPAIR_TEMPLATE\n",
    "        )\n",
    "\n",
    "    async def get_response(self, question, time, old_SQL, explanation, script_tables):\n",
    "        # print(COMPANY_INFO_PROMPT.format(context=data, question=question))\n",
    "        return await self.llm_chain.arun({\"question\": question, \"time\": time, \"old_SQL\": old_SQL, \"explanation\": explanation, \"script_tables\": script_tables})\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T05:22:37.635793Z",
     "start_time": "2024-07-12T05:22:37.633378Z"
    }
   },
   "id": "328421d158f0dce0",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class QdrantSchema:\n",
    "    def __init__(self, schema_file, qdrant_host, qdrant_port, collection_name) -> None:\n",
    "        \n",
    "        self.schema_file = schema_file\n",
    "        list_field, metadata = self.get_data()\n",
    "        # print(list_sector)\n",
    "        self.doc_search = self.init_embedding_store(list_field, metadata, qdrant_host, qdrant_port, collection_name)\n",
    "    \n",
    "    def get_data(self):\n",
    "        with open(self.schema_file) as fp:\n",
    "            data = json.load(fp)\n",
    "\n",
    "        self.schema_json = data\n",
    "\n",
    "        list_field = []\n",
    "        metadata = []\n",
    "        for table, infor in data.items():\n",
    "            for item in infor[\"fields\"]:\n",
    "                list_field.append(item['explanation'].split(', ví dụ:')[0])\n",
    "                # metadata.append([{'schema': infor['schema']}, {'table': table}, {'field': item['field']}, {'explanation': item['explanation']}, {'key': item['key']}, {'type': item['type']}])\n",
    "                metadata.append({'schema': infor['schema'], 'table': table, 'field': item['field'], 'explanation': item['explanation'], 'key': item['key'], 'type': item['type']})\n",
    "        \n",
    "        return list_field, metadata\n",
    "\n",
    "    def get_list_exist(self, qdrant_client, collection_name, emb):\n",
    "        res = qdrant_client.get_collections()\n",
    "        is_exist = False\n",
    "        for cl in res.collections:\n",
    "            if cl.name==collection_name:\n",
    "                is_exist = True\n",
    "                break\n",
    "        # return False, []\n",
    "        list_page_docs = []\n",
    "        if is_exist:\n",
    "            data =qdrant_client.search(\n",
    "                collection_name=collection_name,\n",
    "                query_vector=emb,\n",
    "                with_vectors=False,\n",
    "                with_payload=True,\n",
    "                limit=1000000\n",
    "            )\n",
    "            for doc in data:\n",
    "                list_page_docs.append(doc.payload['page_content'])\n",
    "        return is_exist, list_page_docs\n",
    "\n",
    "\n",
    "\n",
    "    def remove_not_exist(self, qdrant_client, collection_name, sample_list, emb):\n",
    "        res = qdrant_client.get_collections()\n",
    "        is_exist = False\n",
    "        for cl in res.collections:\n",
    "            if cl.name==collection_name:\n",
    "                is_exist = True\n",
    "                break\n",
    "\n",
    "        if is_exist:\n",
    "            data = qdrant_client.search(\n",
    "                collection_name=collection_name,\n",
    "                query_vector=emb,\n",
    "                with_vectors=False,\n",
    "                with_payload=True,\n",
    "                limit=1000000\n",
    "            )\n",
    "        samples = [x for x in sample_list]\n",
    "\n",
    "        for doc in data:\n",
    "            if str(doc.payload['page_content']) not in samples:\n",
    "                # delete this one \n",
    "                print(f\"Delete sample: {str(doc.payload['page_content'])}\")\n",
    "                qdrant_client.delete(\n",
    "                    collection_name=collection_name,\n",
    "                    points_selector=models.PointIdsList(\n",
    "                        points=[doc.id],\n",
    "                    ),\n",
    "                    wait=True\n",
    "                )\n",
    "\n",
    "\n",
    "    def init_embedding_store(self, texts: List[str], metadatas: List[str], qdrant_host: str, qdrant_port: int, collection_name: str) -> Qdrant:\n",
    "        embeddings = OpenAIEmbeddings(deployment=\"text-embedding-ada-002\")\n",
    "        qdrant_client = QdrantClient(host=qdrant_host, port=qdrant_port, timeout=None)\n",
    "        sample_emb = embeddings.embed_query('Doanh thu của 1 quý trước')\n",
    "        is_exist, exists =self.get_list_exist(qdrant_client, collection_name, sample_emb)\n",
    "        if not is_exist:\n",
    "            qdrant_client.recreate_collection(\n",
    "                collection_name=collection_name,\n",
    "                vectors_config=models.VectorParams(\n",
    "                    size=1536, distance=models.Distance.COSINE\n",
    "                ))\n",
    "        \n",
    "        self.remove_not_exist(qdrant_client, collection_name, texts, sample_emb)\n",
    "        docsearch = Qdrant(embeddings=embeddings, client=qdrant_client, collection_name=collection_name)\n",
    "        _texts = []\n",
    "        _metadatas = []\n",
    "        # filter existed documents\n",
    "        for text, metadata in zip(texts, metadatas):\n",
    "            if text not in exists:\n",
    "                _texts.append(text)\n",
    "                _metadatas.append(metadata)\n",
    "\n",
    "        chunks_text = [_texts[x:x+15] for x in range(0, len(_texts), 15)]\n",
    "        chunks_meta = [_metadatas[x:x+15] for x in range(0, len(_metadatas), 15)]\n",
    "\n",
    "        for i in tqdm(range(len(chunks_text))):\n",
    "            docsearch.add_texts(chunks_text[i],chunks_meta[i], batch_size=15)\n",
    "\n",
    "        return docsearch\n",
    "\n",
    "    def return_tables(self, question, top_k=1):\n",
    "        data = self.doc_search.similarity_search_with_score(query=text_normalize(question), k=top_k)\n",
    "        # print(f'QD: {data}')\n",
    "        script = ''\n",
    "        res = pd.DataFrame(data=[data[i][0].metadata for i in range(len(data))])\n",
    "        for table in self.schema_json:\n",
    "            if table in res.table.to_list():\n",
    "                script+= f'''Create table {self.schema_json[table]['schema']}.{table} -- {self.schema_json[table]['description']} ( \\n'''\n",
    "                for field in self.schema_json[table]['fields']:\n",
    "                    if field['field'] in res.field.to_list() or field['default'] == 1:\n",
    "                        script += f'''\\t{field['field']}\\t{field['type']} {field['key'] if field['key'] else \"\"} -- {field['explanation']} \\n'''\n",
    "                script+= ')\\n\\n'\n",
    "        return {'script_tables': script, 'question': question, 'fields': res.field.to_list()}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T05:22:38.218431Z",
     "start_time": "2024-07-12T05:22:38.214237Z"
    }
   },
   "id": "b75a0d52e6d2a186",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delete sample: Tín hiệu kỹ thuật đưa ra từ chỉ số RSI của công ty, mã chứng khoán, doanh nghiệp, tập đoàn. ví dụ: mua, bán, trung tính\n",
      "Delete sample: Tín hiệu kỹ thuật đưa ra từ chỉ số MACD của công ty, mã chứng khoán, doanh nghiệp, tập đoàn. ví dụ: mua, bán, trung tính\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.80it/s]\n"
     ]
    }
   ],
   "source": [
    "from db.session import get_postgres_engine\n",
    "SQLgenerator = GenerateSQL(model_name='gpt-4')\n",
    "SQLrepairer = RepairSQL(model_name='gpt-4')\n",
    "\n",
    "qdrant_schema = QdrantSchema(schema_file='/Users/hieunguyen/DATN/gensql/data/filter_schema.json',\n",
    "                             qdrant_host=os.environ.get('QDRANT_HOST'),\n",
    "                             qdrant_port=os.environ.get('QDRANT_PORT'),\n",
    "                             collection_name='filter_schema')\n",
    "\n",
    "postgres_engine = get_postgres_engine()\n",
    "with open(\"/Users/hieunguyen/DATN/gensql/data/mapping_field_name.json\", \"r\") as json_file:\n",
    "    mapping_field_name = json.load(json_file)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T05:22:40.156924Z",
     "start_time": "2024-07-12T05:22:39.009610Z"
    }
   },
   "id": "9fad157dcfb69b9c",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import re\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "def process_SQL(response, fields, error=False):\n",
    "    if \"```sql\" in response:\n",
    "        response = response.split(\"```sql\")[1]\n",
    "        # print('debug1: ', response)\n",
    "        response = response.split(\"```\")[0]\n",
    "        # print('debug2: ', response)\n",
    "        response = response.strip()\n",
    "        # print('debug3: ', response)\n",
    "    if response[-1] != ';':\n",
    "        response += ';'\n",
    "        # print('debug4: ', response)\n",
    "    if not error:\n",
    "        pattern = r\"trading_time = '(\\d{4}-\\d{2}-\\d{2})'\"\n",
    "        match = re.search(pattern, response)\n",
    "        if match:\n",
    "            query_day = match.group(1).strip()\n",
    "            # print(f'Query day: {query_day}')\n",
    "            session = sessionmaker(postgres_engine)\n",
    "            SQL = f\"\"\"SELECT date\n",
    "                        FROM public.dim_date\n",
    "                        WHERE date BETWEEN TIMESTAMP '{query_day}' - INTERVAL '7 days' AND TIMESTAMP '{query_day}'\n",
    "                        and is_holiday = 'N'\n",
    "                        ORDER BY date desc\n",
    "                        limit 1;\"\"\"\n",
    "            # print(f'SQL: {SQL}')\n",
    "            with session() as s:\n",
    "                result = s.execute(SQL)\n",
    "            rows = result.unique().all()\n",
    "            # print(f'Rows: {rows}')\n",
    "            last_trading_day = [dict(zip(result.keys(), rows[i])) for i in range(len(rows))][0]['date'].strftime(\"%Y-%m-%d\")\n",
    "            # print('Last trading day: ', last_trading_day)\n",
    "            response = response.replace(query_day, last_trading_day)\n",
    "            # print(f'Query day shift -1: {query_day};\\t Last trading day: {last_trading_day}')\n",
    "\n",
    "        new_select = 'SELECT symbol'\n",
    "        appended = ['symbol']\n",
    "        pattern = r'WHERE\\s+(.*?)\\n'\n",
    "        match = re.search(pattern, response, re.IGNORECASE | re.DOTALL)\n",
    "        where_claude = None\n",
    "        if match is not None:\n",
    "            where_claude = match.group(1).strip()\n",
    "        else:\n",
    "            pattern = r'WHERE\\s+(.*?);'\n",
    "            match = re.search(pattern, response, re.IGNORECASE | re.DOTALL)\n",
    "            if match is not None:\n",
    "                where_claude = match.group(1).strip()\n",
    "        where_claude_appended = where_claude\n",
    "        # print(f'Where cluase 1 : {where_claude}')\n",
    "        for field in fields:\n",
    "            if (f' {field}' in response) and (field not in appended):\n",
    "                if f', {field}' not in response:\n",
    "                    new_select += f', {field}'\n",
    "                \n",
    "                if where_claude is not None:\n",
    "                    if f'{field} IS NOT NULL' not in response:\n",
    "                        where_claude_appended += f'\\nAND {field} IS NOT NULL'\n",
    "                        # print(f'Where cluase 2 : {where_claude_appended}')\n",
    "            \n",
    "                appended.append(field)\n",
    "            \n",
    "            if (f'{field}' in response) and (field not in appended):\n",
    "                if where_claude is not None:\n",
    "                    if f'{field} IS NOT NULL' not in response:\n",
    "                        where_claude_appended += f'\\nAND {field} IS NOT NULL'\n",
    "                        # print(f'Where cluase 3 : {where_claude_appended}')\n",
    "            \n",
    "                appended.append(field)\n",
    "        \n",
    "        if 'GROUP BY' not in response:\n",
    "            for field in ['qtr_number', 'year_number', 'quarter_year_name', 'trading_time']:\n",
    "                if (f' {field}' in response) and (field not in appended):\n",
    "                    if f', {field}' not in response:\n",
    "                        new_select += f', {field}'\n",
    "                        appended.append(field)\n",
    "\n",
    "        response = response.replace('SELECT symbol', new_select)\n",
    "        # print(f'New select: {response}')\n",
    "        if where_claude is not None:\n",
    "            response = response.replace(where_claude, where_claude_appended)\n",
    "    return response"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T05:22:50.845743Z",
     "start_time": "2024-07-12T05:22:50.841784Z"
    }
   },
   "id": "f38256201d2311da",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from decimal import Decimal\n",
    "from typing import Dict\n",
    "\n",
    "\n",
    "def process_table(query_result: List[Dict]) -> str :\n",
    "    df = pd.DataFrame(query_result)#.to_html(index=False)\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype==Decimal:\n",
    "            try:\n",
    "                df[column] = df[column].astype(float)\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "    df = df.round(2)\n",
    "    rename_dict = {}\n",
    "    for column in df.columns:\n",
    "        try:\n",
    "            new_name = mapping_field_name[column]\n",
    "        except:\n",
    "            new_name = column\n",
    "\n",
    "        if 'Tỷ' in new_name:\n",
    "            df[column] = df[column]/1e9\n",
    "            df[column] = df[column].astype(float)\n",
    "            df[column] = df[column].apply(lambda x: \"{:,.2f}\".format(x))\n",
    "        elif (df[column].dtype == float) or (df[column].dtype == int):\n",
    "            if (column != 'year_number') and (column != 'qtr_number'):\n",
    "                if any(df[column] >= 1e9) or any(df[column] <= -1e9):\n",
    "                    df[column] = df[column]/1e9\n",
    "                    df[column] = df[column].astype(float)\n",
    "                    new_name += ' (Tỷ)'\n",
    "                    df[column] = df[column].apply(lambda x: \"{:,.2f}\".format(x))\n",
    "                else:\n",
    "                    df[column] = df[column].apply(lambda x: \"{:,}\".format(x))\n",
    "        \n",
    "        rename_dict[column] = new_name\n",
    "\n",
    "    df = df.rename(columns=rename_dict)\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T05:22:51.910145Z",
     "start_time": "2024-07-12T05:22:51.907591Z"
    }
   },
   "id": "50e27d52588c5194",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "async def symbol_filter(native_query: str = \"\", max_try: int = 2, debug: bool = False, date_time: str = None):\n",
    "    executed_params = {}\n",
    "    executed_params['native_query'] = native_query\n",
    "    response = {}\n",
    "    if debug:\n",
    "        response['executed_params'] = executed_params\n",
    "\n",
    "    # get current time\n",
    "    if date_time is None:\n",
    "        now = datetime.now()\n",
    "        date_time = (now + timedelta(hours=7)).strftime(\"%Y-%m-%d\")# + f' Q{1 + now.month//4}-{now.year}'\n",
    "    print(f'Current time: {date_time}')\n",
    "\n",
    "    # get relevant schema\n",
    "    top_k = 15\n",
    "    rel_schema = qdrant_schema.return_tables(native_query, top_k=top_k)\n",
    "    rel_schema['fields'].append('close_price')\n",
    "    print(f\"Câu hỏi: {rel_schema['question']}\")\n",
    "    print(f\"Top 15 trường phù hợp với câu hỏi: {rel_schema['fields']}\")\n",
    "\n",
    "    native_query = native_query.replace('pe', 'p/e').replace('pb', 'p/b').replace('PE', 'P/E').replace('PE', 'P/E')\n",
    "    if 'sma' not in native_query:\n",
    "        native_query = native_query.replace('ma', 'sma')\n",
    "    if 'SMA' not in native_query:\n",
    "        native_query = native_query.replace('MA', 'SMA')\n",
    "    print(f'Native query: {native_query}')\n",
    "\n",
    "    # Generate SQL and query DB\n",
    "    error = False\n",
    "    while max_try > 0:\n",
    "        #  Generate SQL\n",
    "        if not error:\n",
    "            try:\n",
    "                SQL = await SQLgenerator.get_response(question=native_query,\n",
    "                                                time=date_time,\n",
    "                                                script_tables=rel_schema['script_tables'])\n",
    "                if \"SELECT\" not in SQL:\n",
    "                    print(f'Generated SQL:\\n{SQL}')\n",
    "                    response['response'] = 'Hiện tại em không có thông tin để trả lời câu hỏi.'\n",
    "                    print(f\"Response: {response['response']}\")\n",
    "                    return response\n",
    "                # print('*1.1*SQL:', SQL)\n",
    "                SQL = process_SQL(SQL, fields=rel_schema['fields'])\n",
    "                # print('*1*SQL:', SQL)\n",
    "\n",
    "                if \"IS NOT NULL\" not in SQL:\n",
    "                    # print(f'Old SQL:\\n{SQL}')\n",
    "                    SQL = await SQLrepairer.get_response(question=native_query,\n",
    "                                            time=date_time,\n",
    "                                            old_SQL=SQL,\n",
    "                                            explanation=\"Bạn cần lọc bỏ các giá trị NULL\",\n",
    "                                            script_tables=rel_schema['script_tables'])\n",
    "                    # print('*2.1*SQL :', SQL)\n",
    "                    SQL = process_SQL(SQL, fields=rel_schema['fields'])\n",
    "                    # print('*2*SQL :', SQL)\n",
    "\n",
    "            except Exception as e:\n",
    "                response['error'] = 'API_RATE_LIMIT'\n",
    "                print(e)\n",
    "                return response\n",
    "        else:\n",
    "            try:\n",
    "                SQL = await SQLrepairer.get_response(question=native_query,\n",
    "                                            time=date_time,\n",
    "                                            old_SQL=SQL,\n",
    "                                            explanation=explanation,\n",
    "                                            script_tables=rel_schema['script_tables'])\n",
    "                # print('*3.1*SQL:', SQL)\n",
    "                SQL = process_SQL(SQL, fields=rel_schema['fields'], error=True)\n",
    "                # print('*3*SQL:', SQL)\n",
    "                \n",
    "            except Exception as e:\n",
    "                response['error'] = 'API_RATE_LIMIT'\n",
    "                print(e)\n",
    "                return response\n",
    "        max_try -= 1\n",
    "        print(f'Generated SQL:\\n{SQL}')\n",
    "        \n",
    "        # Query DB\n",
    "\n",
    "        try:\n",
    "            session = sessionmaker(postgres_engine)\n",
    "            with session() as s:\n",
    "                result = s.execute(SQL)\n",
    "            rows = result.unique().all()[:10]\n",
    "            query_result = [dict(zip(result.keys(), rows[i])) for i in range(len(rows))]\n",
    "            print(f'Query result:\\n{query_result}')\n",
    "            return query_result\n",
    "\n",
    "        # repair\n",
    "        except Exception as e:\n",
    "            with session() as s:\n",
    "                s.execute(\"ROLLBACK\")\n",
    "            error = True\n",
    "            query_result = str(e)\n",
    "            max_try -= 1\n",
    "            explanation = query_result\n",
    "            if 'does not exist' in query_result:\n",
    "                print(f'Câu SQL không phù hợp với câu hỏi: {query_result}')\n",
    "                response['response'] = 'Hiện tại em không có thông tin để trả lời câu hỏi.'\n",
    "                print(f\"Response: {response['response']}\")\n",
    "                return query_result\n",
    "            print(f'Query result:\\n{query_result}')\n",
    "\n",
    "        # print(f'Generated SQL:\\n{SQL}')\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T05:22:52.672500Z",
     "start_time": "2024-07-12T05:22:52.670332Z"
    }
   },
   "id": "750f5a71ce6fb78a",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current time: 2024-07-12\n",
      "Câu hỏi: Top 3 mã có giá trị giao dịch lớn nhất trong tháng này\n",
      "Top 15 trường phù hợp với câu hỏi: ['accumulated_val_1m', 'accumulated_val_1w', 'accumulated_val_2w', 'loi_nhuan', 'trading_time', 'doanh_thu', 'doanh_thu', 'loi_nhuan', 'accumulated_val', 'close_price', 'smg', 'ty_le_tang_truong_loi_nhuan_2_qtr', 'ty_le_tang_truong_loi_nhuan_1_y', 'ty_le_tang_truong_loi_nhuan_1_qtr', 'ty_le_tang_truong_doanh_thu_2_qtr', 'close_price']\n",
      "Native query: Top 3 mã có giá trị giao dịch lớn nhất trong tháng này\n",
      "Generated SQL:\n",
      "SELECT symbol, trading_time, accumulated_val\n",
      "FROM public.calculate_filter_bien_dong_gia_va_khoi_luong_daily_1d0h0m_1\n",
      "WHERE trading_time BETWEEN '2024-07-01' AND '2024-07-12'\n",
      "AND trading_time IS NOT NULL\n",
      "AND accumulated_val IS NOT NULL\n",
      "ORDER BY accumulated_val DESC\n",
      "LIMIT 3;\n",
      "Query result:\n",
      "[{'symbol': 'MWG', 'trading_time': datetime.datetime(2024, 7, 1, 0, 0), 'accumulated_val': Decimal('1396.877439999997')}, {'symbol': 'FPT', 'trading_time': datetime.datetime(2024, 7, 9, 0, 0), 'accumulated_val': Decimal('1327.0239800000013')}, {'symbol': 'FPT', 'trading_time': datetime.datetime(2024, 7, 4, 0, 0), 'accumulated_val': Decimal('1088.4880400000006')}]\n"
     ]
    }
   ],
   "source": [
    "df_result = await symbol_filter('Top 3 mã có giá trị giao dịch lớn nhất trong tháng này')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T05:26:29.263784Z",
     "start_time": "2024-07-12T05:26:23.500355Z"
    }
   },
   "id": "5097125c82d01d18",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "    Mã Thời gian GD Tổng GTGD trong ngày\n0  MWG   2024-07-01             1,396.88\n1  FPT   2024-07-09             1,327.02\n2  FPT   2024-07-04             1,088.49",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Mã</th>\n      <th>Thời gian GD</th>\n      <th>Tổng GTGD trong ngày</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>MWG</td>\n      <td>2024-07-01</td>\n      <td>1,396.88</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>FPT</td>\n      <td>2024-07-09</td>\n      <td>1,327.02</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>FPT</td>\n      <td>2024-07-04</td>\n      <td>1,088.49</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_process = process_table(df_result)\n",
    "df_process"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T05:26:35.289659Z",
     "start_time": "2024-07-12T05:26:35.284050Z"
    }
   },
   "id": "b66c8755c3fa6676",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T00:33:48.219363Z",
     "start_time": "2024-07-12T00:33:48.209672Z"
    }
   },
   "id": "e650d766ef194db0",
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
