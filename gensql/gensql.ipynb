{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain import LLMChain\n",
    "\n",
    "from gensql.langchain.prompt_layer import PromptLayerCustom\n",
    "from gensql.langchain.prompt import *\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from typing import List\n",
    "from qdrant_client.http import models\n",
    "from langchain.vectorstores import Qdrant\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from underthesea import text_normalize\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "env_path = Path(\".\") / \"/Users/hieunguyen/DATN/.env\"\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "os.environ[\"EMBEDDING_OPENAI_API_KEY\"] = os.environ.get(\"EMBEDDING_OPENAI_API_KEY\")\n",
    "\n",
    "import promptlayer\n",
    "# promptlayer.utils.URL_API_PROMPTLAYER\n",
    "promptlayer.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "from langchain.embeddings import openai\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "import json"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-30T16:11:24.147103Z",
     "start_time": "2024-06-30T16:11:24.143266Z"
    }
   },
   "id": "30aa06a52527f70e",
   "execution_count": 145
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "openai_key = os.environ.get(\"OPENAI_API_KEY_WITHOUT_AZURE\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-30T16:11:24.151302Z",
     "start_time": "2024-06-30T16:11:24.147570Z"
    }
   },
   "id": "936b21265e831c2e",
   "execution_count": 146
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class CheckSQL:\n",
    "    def __init__(self, model_name) -> None:\n",
    "        self.model_name = model_name\n",
    "\n",
    "        self.llm = PromptLayerCustom(model_name=self.model_name,\n",
    "                                     openai_api_key=openai_key,\n",
    "                                     temperature=0,\n",
    "                                     max_tokens=512,\n",
    "                                     pl_tags=['filter_check_SQL', 'api-server']\n",
    "                                    )\n",
    "        self.llm_chain = LLMChain(\n",
    "            llm=self.llm,\n",
    "            prompt=CHECKSQL_TEMPLATE\n",
    "        )\n",
    "\n",
    "    async def get_response(self, question, time, SQL, script_tables):\n",
    "        # print(ANALYZER_TEMPLATE.format(question=question, time=time, script_tables=script_tables))\n",
    "        return await self.llm_chain.arun({\"question\": question, \"time\": time, \"SQL\": SQL, \"script_tables\": script_tables})\n",
    "    \n",
    "class GenerateSQL:\n",
    "    def __init__(self, model_name) -> None:\n",
    "        self.model_name = model_name\n",
    "\n",
    "        self.llm = PromptLayerCustom(model_name=self.model_name,\n",
    "                                     openai_api_key=openai_key,\n",
    "                                     temperature=0,\n",
    "                                     max_tokens=512,\n",
    "                                     pl_tags=['filter_generate_SQL', 'api-server']\n",
    "                                    )\n",
    "        self.llm_chain = LLMChain(\n",
    "            llm=self.llm,\n",
    "            prompt=GENERATE_SQL_TEMPLATE\n",
    "        )\n",
    "\n",
    "    async def get_response(self, question, time, script_tables):\n",
    "        # print(COMPANY_INFO_PROMPT.format(context=data, question=question))\n",
    "        return await self.llm_chain.arun({\"question\": question, \"time\": time, \"script_tables\": script_tables})\n",
    "\n",
    "class RepairSQL:\n",
    "    def __init__(self, model_name) -> None:\n",
    "        self.model_name = model_name\n",
    "\n",
    "        self.llm = PromptLayerCustom(model_name=self.model_name,\n",
    "                                     openai_api_key=openai_key,\n",
    "                                     temperature=0,\n",
    "                                     max_tokens=512,\n",
    "                                     pl_tags=['filter_repair_SQL', 'api-server']\n",
    "                                    )\n",
    "        self.llm_chain = LLMChain(\n",
    "            llm=self.llm,\n",
    "            prompt=REPAIR_TEMPLATE\n",
    "        )\n",
    "\n",
    "    async def get_response(self, question, time, old_SQL, explanation, script_tables):\n",
    "        # print(COMPANY_INFO_PROMPT.format(context=data, question=question))\n",
    "        return await self.llm_chain.arun({\"question\": question, \"time\": time, \"old_SQL\": old_SQL, \"explanation\": explanation, \"script_tables\": script_tables})\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-30T16:11:24.157528Z",
     "start_time": "2024-06-30T16:11:24.153595Z"
    }
   },
   "id": "328421d158f0dce0",
   "execution_count": 147
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class QdrantSchema:\n",
    "    def __init__(self, schema_file, qdrant_host, qdrant_port, collection_name) -> None:\n",
    "        \n",
    "        self.schema_file = schema_file\n",
    "        list_field, metadata = self.get_data()\n",
    "        # print(list_sector)\n",
    "        self.doc_search = self.init_embedding_store(list_field, metadata, qdrant_host, qdrant_port, collection_name)\n",
    "    \n",
    "    def get_data(self):\n",
    "        with open(self.schema_file) as fp:\n",
    "            data = json.load(fp)\n",
    "\n",
    "        self.schema_json = data\n",
    "\n",
    "        list_field = []\n",
    "        metadata = []\n",
    "        for table, infor in data.items():\n",
    "            for item in infor[\"fields\"]:\n",
    "                list_field.append(item['explanation'].split(', ví dụ:')[0])\n",
    "                # metadata.append([{'schema': infor['schema']}, {'table': table}, {'field': item['field']}, {'explanation': item['explanation']}, {'key': item['key']}, {'type': item['type']}])\n",
    "                metadata.append({'schema': infor['schema'], 'table': table, 'field': item['field'], 'explanation': item['explanation'], 'key': item['key'], 'type': item['type']})\n",
    "        \n",
    "        return list_field, metadata\n",
    "\n",
    "    def get_list_exist(self, qdrant_client, collection_name, emb):\n",
    "        res = qdrant_client.get_collections()\n",
    "        is_exist = False\n",
    "        for cl in res.collections:\n",
    "            if cl.name==collection_name:\n",
    "                is_exist = True\n",
    "                break\n",
    "        # return False, []\n",
    "        list_page_docs = []\n",
    "        if is_exist:\n",
    "            data =qdrant_client.search(\n",
    "                collection_name=collection_name,\n",
    "                query_vector=emb,\n",
    "                with_vectors=False,\n",
    "                with_payload=True,\n",
    "                limit=1000000\n",
    "            )\n",
    "            for doc in data:\n",
    "                list_page_docs.append(doc.payload['page_content'])\n",
    "        return is_exist, list_page_docs\n",
    "\n",
    "\n",
    "\n",
    "    def remove_not_exist(self, qdrant_client, collection_name, sample_list, emb):\n",
    "        res = qdrant_client.get_collections()\n",
    "        is_exist = False\n",
    "        for cl in res.collections:\n",
    "            if cl.name==collection_name:\n",
    "                is_exist = True\n",
    "                break\n",
    "\n",
    "        if is_exist:\n",
    "            data = qdrant_client.search(\n",
    "                collection_name=collection_name,\n",
    "                query_vector=emb,\n",
    "                with_vectors=False,\n",
    "                with_payload=True,\n",
    "                limit=1000000\n",
    "            )\n",
    "        samples = [x for x in sample_list]\n",
    "\n",
    "        for doc in data:\n",
    "            if str(doc.payload['page_content']) not in samples:\n",
    "                # delete this one \n",
    "                print(f\"Delete sample: {str(doc.payload['page_content'])}\")\n",
    "                qdrant_client.delete(\n",
    "                    collection_name=collection_name,\n",
    "                    points_selector=models.PointIdsList(\n",
    "                        points=[doc.id],\n",
    "                    ),\n",
    "                    wait=True\n",
    "                )\n",
    "\n",
    "\n",
    "    def init_embedding_store(self, texts: List[str], metadatas: List[str], qdrant_host: str, qdrant_port: int, collection_name: str) -> Qdrant:\n",
    "        embeddings = OpenAIEmbeddings(deployment=\"text-embedding-ada-002\")\n",
    "        qdrant_client = QdrantClient(host=qdrant_host, port=qdrant_port, timeout=None)\n",
    "        sample_emb = embeddings.embed_query('Doanh thu của 1 quý trước')\n",
    "        is_exist, exists =self.get_list_exist(qdrant_client, collection_name, sample_emb)\n",
    "        if not is_exist:\n",
    "            qdrant_client.recreate_collection(\n",
    "                collection_name=collection_name,\n",
    "                vectors_config=models.VectorParams(\n",
    "                    size=1536, distance=models.Distance.COSINE\n",
    "                ))\n",
    "        \n",
    "        self.remove_not_exist(qdrant_client, collection_name, texts, sample_emb)\n",
    "        docsearch = Qdrant(embeddings=embeddings, client=qdrant_client, collection_name=collection_name)\n",
    "        _texts = []\n",
    "        _metadatas = []\n",
    "        # filter existed documents\n",
    "        for text, metadata in zip(texts, metadatas):\n",
    "            if text not in exists:\n",
    "                _texts.append(text)\n",
    "                _metadatas.append(metadata)\n",
    "\n",
    "        chunks_text = [_texts[x:x+15] for x in range(0, len(_texts), 15)]\n",
    "        chunks_meta = [_metadatas[x:x+15] for x in range(0, len(_metadatas), 15)]\n",
    "\n",
    "        for i in tqdm(range(len(chunks_text))):\n",
    "            docsearch.add_texts(chunks_text[i],chunks_meta[i], batch_size=15)\n",
    "\n",
    "        return docsearch\n",
    "\n",
    "    def return_tables(self, question, top_k=1):\n",
    "        data = self.doc_search.similarity_search_with_score(query=text_normalize(question), k=top_k)\n",
    "        print(f'QD: {data}')\n",
    "        script = ''\n",
    "        res = pd.DataFrame(data=[data[i][0].metadata for i in range(len(data))])\n",
    "        for table in self.schema_json:\n",
    "            if table in res.table.to_list():\n",
    "                script+= f'''Create table {self.schema_json[table]['schema']}.{table} -- {self.schema_json[table]['description']} ( \\n'''\n",
    "                for field in self.schema_json[table]['fields']:\n",
    "                    if field['field'] in res.field.to_list() or field['default'] == 1:\n",
    "                        script += f'''\\t{field['field']}\\t{field['type']} {field['key'] if field['key'] else \"\"} -- {field['explanation']} \\n'''\n",
    "                script+= ')\\n\\n'\n",
    "        return {'script_tables': script, 'question': question, 'fields': res.field.to_list()}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-30T16:11:24.170617Z",
     "start_time": "2024-06-30T16:11:24.161607Z"
    }
   },
   "id": "b75a0d52e6d2a186",
   "execution_count": 148
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.01s/it]\n"
     ]
    }
   ],
   "source": [
    "from db.session import get_postgres_engine\n",
    "SQLgenerator = GenerateSQL(model_name='gpt-4')\n",
    "SQLrepairer = RepairSQL(model_name='gpt-4')\n",
    "\n",
    "qdrant_schema = QdrantSchema(schema_file='/Users/hieunguyen/DATN/gensql/data/filter_schema.json',\n",
    "                             qdrant_host=os.environ.get('QDRANT_HOST'),\n",
    "                             qdrant_port=os.environ.get('QDRANT_PORT'),\n",
    "                             collection_name='filter_schema')\n",
    "\n",
    "postgres_engine = get_postgres_engine()\n",
    "with open(\"/Users/hieunguyen/DATN/gensql/data/mapping_field_name.json\", \"r\") as json_file:\n",
    "    mapping_field_name = json.load(json_file)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-30T16:11:25.720944Z",
     "start_time": "2024-06-30T16:11:24.169691Z"
    }
   },
   "id": "9fad157dcfb69b9c",
   "execution_count": 149
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import re\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "def process_SQL(response, fields, error=False):\n",
    "    if \"```sql\" in response:\n",
    "        response = response.split(\"```sql\")[1]\n",
    "        print('debug1: ', response)\n",
    "        response = response.split(\"```\")[0]\n",
    "        print('debug2: ', response)\n",
    "        response = response.strip()\n",
    "        print('debug3: ', response)\n",
    "    if response[-1] != ';':\n",
    "        response += ';'\n",
    "        print('debug4: ', response)\n",
    "    if not error:\n",
    "        pattern = r\"trading_time = '(\\d{4}-\\d{2}-\\d{2})'\"\n",
    "        match = re.search(pattern, response)\n",
    "        if match:\n",
    "            query_day = match.group(1).strip()\n",
    "            print(f'Query day: {query_day}')\n",
    "            session = sessionmaker(postgres_engine)\n",
    "            SQL = f\"\"\"SELECT date\n",
    "                        FROM public.dim_date\n",
    "                        WHERE date BETWEEN TIMESTAMP '{query_day}' - INTERVAL '7 days' AND TIMESTAMP '{query_day}'\n",
    "                        and is_holiday = 'N'\n",
    "                        ORDER BY date desc\n",
    "                        limit 1;\"\"\"\n",
    "            print(f'SQL: {SQL}')\n",
    "            with session() as s:\n",
    "                result = s.execute(SQL)\n",
    "            rows = result.unique().all()\n",
    "            print(f'Rows: {rows}')\n",
    "            last_trading_day = [dict(zip(result.keys(), rows[i])) for i in range(len(rows))][0]['date'].strftime(\"%Y-%m-%d\")\n",
    "            print('Last trading day: ', last_trading_day)\n",
    "            response = response.replace(query_day, last_trading_day)\n",
    "            print(f'Query day shift -1: {query_day};\\t Last trading day: {last_trading_day}')\n",
    "\n",
    "        new_select = 'SELECT symbol'\n",
    "        appended = ['symbol']\n",
    "        pattern = r'WHERE\\s+(.*?)\\n'\n",
    "        match = re.search(pattern, response, re.IGNORECASE | re.DOTALL)\n",
    "        where_claude = None\n",
    "        if match is not None:\n",
    "            where_claude = match.group(1).strip()\n",
    "        else:\n",
    "            pattern = r'WHERE\\s+(.*?);'\n",
    "            match = re.search(pattern, response, re.IGNORECASE | re.DOTALL)\n",
    "            if match is not None:\n",
    "                where_claude = match.group(1).strip()\n",
    "        where_claude_appended = where_claude\n",
    "        print(f'Where cluase 1 : {where_claude}')\n",
    "        for field in fields:\n",
    "            if (f' {field}' in response) and (field not in appended):\n",
    "                if f', {field}' not in response:\n",
    "                    new_select += f', {field}'\n",
    "                \n",
    "                if where_claude is not None:\n",
    "                    if f'{field} IS NOT NULL' not in response:\n",
    "                        where_claude_appended += f'\\nAND {field} IS NOT NULL'\n",
    "                        print(f'Where cluase 2 : {where_claude_appended}')\n",
    "            \n",
    "                appended.append(field)\n",
    "            \n",
    "            if (f'{field}' in response) and (field not in appended):\n",
    "                if where_claude is not None:\n",
    "                    if f'{field} IS NOT NULL' not in response:\n",
    "                        where_claude_appended += f'\\nAND {field} IS NOT NULL'\n",
    "                        print(f'Where cluase 3 : {where_claude_appended}')\n",
    "            \n",
    "                appended.append(field)\n",
    "        \n",
    "        if 'GROUP BY' not in response:\n",
    "            for field in ['qtr_number', 'year_number', 'quarter_year_name', 'trading_time']:\n",
    "                if (f' {field}' in response) and (field not in appended):\n",
    "                    if f', {field}' not in response:\n",
    "                        new_select += f', {field}'\n",
    "                        appended.append(field)\n",
    "\n",
    "        response = response.replace('SELECT symbol', new_select)\n",
    "        print(f'New select: {response}')\n",
    "        if where_claude is not None:\n",
    "            response = response.replace(where_claude, where_claude_appended)\n",
    "    return response"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-30T16:11:25.728485Z",
     "start_time": "2024-06-30T16:11:25.725820Z"
    }
   },
   "id": "f38256201d2311da",
   "execution_count": 150
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from decimal import Decimal\n",
    "from typing import Dict\n",
    "\n",
    "\n",
    "def process_table(query_result: List[Dict]) -> str :\n",
    "    df = pd.DataFrame(query_result)#.to_html(index=False)\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype==Decimal:\n",
    "            try:\n",
    "                df[column] = df[column].astype(float)\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "    df = df.round(2)\n",
    "    rename_dict = {}\n",
    "    for column in df.columns:\n",
    "        try:\n",
    "            new_name = mapping_field_name[column]\n",
    "        except:\n",
    "            new_name = column\n",
    "\n",
    "        if 'Tỷ' in new_name:\n",
    "            df[column] = df[column]/1e9\n",
    "            df[column] = df[column].astype(float)\n",
    "            df[column] = df[column].apply(lambda x: \"{:,.2f}\".format(x))\n",
    "        elif (df[column].dtype == float) or (df[column].dtype == int):\n",
    "            if (column != 'year_number') and (column != 'qtr_number'):\n",
    "                if any(df[column] >= 1e9) or any(df[column] <= -1e9):\n",
    "                    df[column] = df[column]/1e9\n",
    "                    df[column] = df[column].astype(float)\n",
    "                    new_name += ' (Tỷ)'\n",
    "                    df[column] = df[column].apply(lambda x: \"{:,.2f}\".format(x))\n",
    "                else:\n",
    "                    df[column] = df[column].apply(lambda x: \"{:,}\".format(x))\n",
    "        \n",
    "        rename_dict[column] = new_name\n",
    "\n",
    "    df = df.rename(columns=rename_dict)\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-30T16:11:25.733713Z",
     "start_time": "2024-06-30T16:11:25.730445Z"
    }
   },
   "id": "50e27d52588c5194",
   "execution_count": 151
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "async def symbol_filter(native_query: str = \"\", max_try: int = 2, debug: bool = False, date_time: str = None):\n",
    "    executed_params = {}\n",
    "    executed_params['native_query'] = native_query\n",
    "    response = {}\n",
    "    if debug:\n",
    "        response['executed_params'] = executed_params\n",
    "\n",
    "    # get current time\n",
    "    if date_time is None:\n",
    "        now = datetime.now()\n",
    "        date_time = (now + timedelta(hours=7)).strftime(\"%Y-%m-%d\")# + f' Q{1 + now.month//4}-{now.year}'\n",
    "    print(f'Current time: {date_time}')\n",
    "\n",
    "    # get relevant schema\n",
    "    top_k = 15\n",
    "    rel_schema = qdrant_schema.return_tables(native_query, top_k=top_k)\n",
    "    rel_schema['fields'].append('close_price')\n",
    "    print(f'Relevant schema: {rel_schema}')\n",
    "\n",
    "    native_query = native_query.replace('pe', 'p/e').replace('pb', 'p/b').replace('PE', 'P/E').replace('PE', 'P/E')\n",
    "    if 'sma' not in native_query:\n",
    "        native_query = native_query.replace('ma', 'sma')\n",
    "    if 'SMA' not in native_query:\n",
    "        native_query = native_query.replace('MA', 'SMA')\n",
    "    print(f'Native query: {native_query}')\n",
    "\n",
    "    # Generate SQL and query DB\n",
    "    error = False\n",
    "    while max_try > 0:\n",
    "        #  Generate SQL\n",
    "        if not error:\n",
    "            try:\n",
    "                SQL = await SQLgenerator.get_response(question=native_query,\n",
    "                                                time=date_time,\n",
    "                                                script_tables=rel_schema['script_tables'])\n",
    "                if \"SELECT\" not in SQL:\n",
    "                    print(f'Generated SQL:\\n{SQL}')\n",
    "                    response['response'] = 'Hiện tại em không có thông tin để trả lời câu hỏi.'\n",
    "                    print(f\"Response: {response['response']}\")\n",
    "                    return response\n",
    "                print('*1.1*SQL:', SQL)\n",
    "                SQL = process_SQL(SQL, fields=rel_schema['fields'])\n",
    "                print('*1*SQL:', SQL)\n",
    "\n",
    "                if \"IS NOT NULL\" not in SQL:\n",
    "                    print(f'Old SQL:\\n{SQL}')\n",
    "                    SQL = await SQLrepairer.get_response(question=native_query,\n",
    "                                            time=date_time,\n",
    "                                            old_SQL=SQL,\n",
    "                                            explanation=\"Bạn cần lọc bỏ các giá trị NULL\",\n",
    "                                            script_tables=rel_schema['script_tables'])\n",
    "                    print('*2.1*SQL :', SQL)\n",
    "                    SQL = process_SQL(SQL, fields=rel_schema['fields'])\n",
    "                    print('*2*SQL :', SQL)\n",
    "\n",
    "            except Exception as e:\n",
    "                response['error'] = 'API_RATE_LIMIT'\n",
    "                print(e)\n",
    "                return response\n",
    "        else:\n",
    "            try:\n",
    "                SQL = await SQLrepairer.get_response(question=native_query,\n",
    "                                            time=date_time,\n",
    "                                            old_SQL=SQL,\n",
    "                                            explanation=explanation,\n",
    "                                            script_tables=rel_schema['script_tables'])\n",
    "                print('*3.1*SQL:', SQL)\n",
    "                SQL = process_SQL(SQL, fields=rel_schema['fields'], error=True)\n",
    "                print('*3*SQL:', SQL)\n",
    "                \n",
    "            except Exception as e:\n",
    "                response['error'] = 'API_RATE_LIMIT'\n",
    "                print(e)\n",
    "                return response\n",
    "        max_try -= 1\n",
    "        print(f'Generated SQL:\\n{SQL}')\n",
    "        \n",
    "        # Query DB\n",
    "\n",
    "        try:\n",
    "            session = sessionmaker(postgres_engine)\n",
    "            with session() as s:\n",
    "                result = s.execute(SQL)\n",
    "            rows = result.unique().all()[:10]\n",
    "            query_result = [dict(zip(result.keys(), rows[i])) for i in range(len(rows))]\n",
    "            print(f'Query result:\\n{query_result}')\n",
    "            return query_result\n",
    "\n",
    "        # repair\n",
    "        except Exception as e:\n",
    "            with session() as s:\n",
    "                s.execute(\"ROLLBACK\")\n",
    "            error = True\n",
    "            query_result = str(e)\n",
    "            max_try -= 1\n",
    "            explanation = query_result\n",
    "            if 'does not exist' in query_result:\n",
    "                print(f'Câu SQL không phù hợp với câu hỏi: {query_result}')\n",
    "                response['response'] = 'Hiện tại em không có thông tin để trả lời câu hỏi.'\n",
    "                print(f\"Response: {response['response']}\")\n",
    "                return query_result\n",
    "            print(f'Query result:\\n{query_result}')\n",
    "\n",
    "        print(f'Generated SQL:\\n{SQL}')\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-30T16:11:25.744Z",
     "start_time": "2024-06-30T16:11:25.738468Z"
    }
   },
   "id": "750f5a71ce6fb78a",
   "execution_count": 152
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current time: 2024-07-01\n",
      "QD: [(Document(page_content='Tỷ lệ tăng trưởng doanh thu so với 5 năm trước', metadata={'explanation': 'Tỷ lệ tăng trưởng doanh thu so với 5 năm trước, ví dụ: -0.67', 'field': 'ty_le_tang_truong_doanh_thu_5_y', 'key': None, 'schema': 'dwh_market', 'table': 'fact_symbol_chi_so_tang_truong_yearly', 'type': 'double precision'}), 0.8148963), (Document(page_content='Doanh thu của 5 năm trước', metadata={'explanation': 'Doanh thu của 5 năm trước, ví dụ: 4,236,069,360,770 (đơn vị: đồng)', 'field': 'doanh_thu_5_y_ago', 'key': None, 'schema': 'dwh_market', 'table': 'fact_symbol_chi_so_tang_truong_yearly', 'type': 'double precision'}), 0.8112711), (Document(page_content='Tỷ lệ tăng trưởng lợi nhuận so với 5 năm trước', metadata={'explanation': 'Tỷ lệ tăng trưởng lợi nhuận so với 5 năm trước, ví dụ: 1.46', 'field': 'ty_le_tang_truong_loi_nhuan_5_y', 'key': None, 'schema': 'dwh_market', 'table': 'fact_symbol_chi_so_tang_truong_yearly', 'type': 'double precision'}), 0.810809), (Document(page_content='giá trị giao dịch trung bình 5 phiên/ngày gần nhất, giá trị giao dịch trung bình trong tuần vừa rồi', metadata={'explanation': 'giá trị giao dịch trung bình 5 phiên/ngày gần nhất, giá trị giao dịch trung bình trong tuần vừa rồi, ví dụ: 7.51 (đơn vị: tỷ đồng)', 'field': 'accumulated_val_1w', 'key': None, 'schema': 'posgres', 'table': 'calculate_filter_bien_dong_gia_va_khoi_luong_daily_1d0h0m_1', 'type': 'numeric'}), 0.8095309), (Document(page_content='Tỷ lệ tăng trưởng eps (lợi nhuận sau thuế phân bổ trên một cổ phiếu) so với 5 năm trước', metadata={'explanation': 'Tỷ lệ tăng trưởng eps (lợi nhuận sau thuế phân bổ trên một cổ phiếu) so với 5 năm trước, ví dụ: 1.46', 'field': 'ty_le_tang_truong_eps_5_y', 'key': None, 'schema': 'dwh_market', 'table': 'fact_symbol_chi_so_tang_truong_yearly', 'type': 'double precision'}), 0.80844384), (Document(page_content='Lợi nhuận của 5 năm trước', metadata={'explanation': 'Lợi nhuận của 5 năm trước, ví dụ: 316,664,795,156 (đơn vị: đồng)', 'field': 'loi_nhuan_5_y_ago', 'key': None, 'schema': 'dwh_market', 'table': 'fact_symbol_chi_so_tang_truong_yearly', 'type': 'double precision'}), 0.80239844), (Document(page_content='eps (lợi nhuận sau thuế phân bổ trên một cổ phiếu) của 5 năm trước', metadata={'explanation': 'eps (lợi nhuận sau thuế phân bổ trên một cổ phiếu) của 5 năm trước, ví dụ: 15,531.16 (đơn vị: đồng)', 'field': 'eps_5_y_ago', 'key': None, 'schema': 'dwh_market', 'table': 'fact_symbol_chi_so_tang_truong_yearly', 'type': 'double precision'}), 0.7978179), (Document(page_content='PB của công ty, mã chứng khoán, doanh nghiệp, tập đoàn.', metadata={'explanation': 'PB của công ty, mã chứng khoán, doanh nghiệp, tập đoàn.', 'field': 'pb', 'key': None, 'schema': 'public_market', 'table': 'fact_symbol_cstc_yearly', 'type': 'double precision'}), 0.79725444), (Document(page_content='PB của công ty, mã chứng khoán, doanh nghiệp, tập đoàn.', metadata={'explanation': 'PB của công ty, mã chứng khoán, doanh nghiệp, tập đoàn.', 'field': 'pb', 'key': None, 'schema': 'public', 'table': 'indicator_signal', 'type': 'double precision'}), 0.79725444), (Document(page_content='Mã chứng khoán, công ty, doanh nghiệp, tập đoàn', metadata={'explanation': 'Mã chứng khoán, công ty, doanh nghiệp, tập đoàn, ví dụ: HPG, vic, vcb,...', 'field': 'symbol', 'key': 'distkey', 'schema': 'dwh_market', 'table': 'fact_symbol_chi_so_tang_truong_quarterly', 'type': 'varchar(65535)'}), 0.7912004), (Document(page_content='Mã chứng khoán, công ty, doanh nghiệp, tập đoàn', metadata={'explanation': 'Mã chứng khoán, công ty, doanh nghiệp, tập đoàn, ví dụ: HPG, vic, vcb,...', 'field': 'symbol', 'key': 'distkey', 'schema': 'dwh_market', 'table': 'fact_symbol_chi_so_tang_truong_yearly', 'type': 'varchar(65535)'}), 0.7912004), (Document(page_content='Mã chứng khoán, công ty, doanh nghiệp, tập đoàn', metadata={'explanation': 'Mã chứng khoán, công ty, doanh nghiệp, tập đoàn, ví dụ: HPG, VIC, VCB,...', 'field': 'symbol', 'key': 'primary key', 'schema': 'posgres', 'table': 'calculate_filter_bien_dong_gia_va_khoi_luong_daily_1d0h0m_1', 'type': 'varchar(20)'}), 0.7912004), (Document(page_content='Giá trị đường trung bình động đơn giản hay Trung bình giá đóng cửa - giá cuối ngày (SMA hay sma) khung 5 ngày', metadata={'explanation': 'Giá trị đường trung bình động đơn giản hay Trung bình giá đóng cửa - giá cuối ngày (SMA hay sma) khung 5 ngày, ví dụ: 8.02 (đơn vị: nghìn đồng)', 'field': 'sma_5', 'key': None, 'schema': 'posgres', 'table': 'calculate_filter_bien_dong_gia_va_khoi_luong_daily_1d0h0m_1', 'type': 'numeric'}), 0.78869206), (Document(page_content='PE của công ty, mã chứng khoán, doanh nghiệp, tập đoàn.', metadata={'explanation': 'PE của công ty, mã chứng khoán, doanh nghiệp, tập đoàn.', 'field': 'pe', 'key': None, 'schema': 'public_market', 'table': 'fact_symbol_cstc_yearly', 'type': 'double precision'}), 0.7876818), (Document(page_content='PE của công ty, mã chứng khoán, doanh nghiệp, tập đoàn.', metadata={'explanation': 'PE của công ty, mã chứng khoán, doanh nghiệp, tập đoàn.', 'field': 'pe', 'key': None, 'schema': 'public', 'table': 'indicator_signal', 'type': 'double precision'}), 0.7876818)]\n",
      "Relevant schema: {'script_tables': 'Create table public_market.fact_symbol_chi_so_tang_truong_yearly -- Chỉ số tăng trưởng doanh thu, lợi nhuận, EPS của các mã chứng khoán, công ty trong khung thời gian: năm ( \\n\\tunique_id\\tvarchar(32)  -- Unique ID \\n\\tyear_number\\tinteger  -- Năm, Year, ví dụ: 2022, 2023,... \\n\\tsymbol\\tvarchar(65535) distkey -- Mã chứng khoán, công ty, doanh nghiệp, tập đoàn, ví dụ: HPG, vic, vcb,... \\n\\tdoanh_thu_5_y_ago\\tdouble precision  -- Doanh thu của 5 năm trước, ví dụ: 4,236,069,360,770 (đơn vị: đồng) \\n\\tty_le_tang_truong_doanh_thu_5_y\\tdouble precision  -- Tỷ lệ tăng trưởng doanh thu so với 5 năm trước, ví dụ: -0.67 \\n\\tloi_nhuan_5_y_ago\\tdouble precision  -- Lợi nhuận của 5 năm trước, ví dụ: 316,664,795,156 (đơn vị: đồng) \\n\\tty_le_tang_truong_loi_nhuan_5_y\\tdouble precision  -- Tỷ lệ tăng trưởng lợi nhuận so với 5 năm trước, ví dụ: 1.46 \\n\\teps_5_y_ago\\tdouble precision  -- eps (lợi nhuận sau thuế phân bổ trên một cổ phiếu) của 5 năm trước, ví dụ: 15,531.16 (đơn vị: đồng) \\n\\tty_le_tang_truong_eps_5_y\\tdouble precision  -- Tỷ lệ tăng trưởng eps (lợi nhuận sau thuế phân bổ trên một cổ phiếu) so với 5 năm trước, ví dụ: 1.46 \\n)\\n\\nCreate table public_market.fact_symbol_chi_so_tang_truong_quarterly -- Chỉ số tăng trưởng doanh thu, lợi nhuận của các mã chứng khoán, công ty trong khung thời gian: quý ( \\n\\tunique_id\\tvarchar(32)  -- Unique ID \\n\\tqtr_number\\tinteger  -- Quý - một năm có 4 quý, ví dụ: 1, 2, 3, 4 \\n\\tyear_number\\tinteger  -- Năm, Year, ví dụ: 2022, 2023,... \\n\\tquarter_year_name\\tvarchar(24)  -- Quý và năm, ví dụ: Q4-2023 \\n\\tsymbol\\tvarchar(65535) distkey -- Mã chứng khoán, công ty, doanh nghiệp, tập đoàn, ví dụ: HPG, vic, vcb,... \\n)\\n\\nCreate table public.calculate_filter_bien_dong_gia_va_khoi_luong_daily_1d0h0m_1 -- Thông tin về biến động về giá đóng cửa và khối lượng giao dịch chứng khoán theo ngày, một dòng là thông tin của 1 mã trong 1 ngày ( \\n\\tsymbol\\tvarchar(20) primary key -- Mã chứng khoán, công ty, doanh nghiệp, tập đoàn, ví dụ: HPG, VIC, VCB,... \\n\\ttrading_time\\ttimestamp primary key -- Ngày giao dịch, phiên giao dịch của mã chứng khoán, ví dụ: 2024-06-03 \\n\\taccumulated_val_1w\\tnumeric  -- giá trị giao dịch trung bình 5 phiên/ngày gần nhất, giá trị giao dịch trung bình trong tuần vừa rồi, ví dụ: 7.51 (đơn vị: tỷ đồng) \\n\\tclose_price\\tnumeric  -- Giá đóng cửa (giá cuối ngày) tại của 1 ngày giao dịch, ví dụ: 7.88 (đơn vị: nghìn đồng) \\n\\tsma_5\\tnumeric  -- Giá trị đường trung bình động đơn giản hay Trung bình giá đóng cửa - giá cuối ngày (SMA hay sma) khung 5 ngày, ví dụ: 8.02 (đơn vị: nghìn đồng) \\n)\\n\\nCreate table public_market.fact_symbol_cstc_yearly -- Biên lãi gộp, roe, eps, pe, pb, ev/ebitda của các mã chứng khoán, công ty trong khung thời gian: năm ( \\n\\tmack\\tvarchar(65535) distkey -- Mã chứng khoán, công ty, doanh nghiệp, tập đoàn, ví dụ: HPG, vic, vcb,... \\n\\tnam\\tinteger  -- Năm, Year, ví dụ: 2022, 2023,... \\n\\tpe\\tdouble precision  -- PE của công ty, mã chứng khoán, doanh nghiệp, tập đoàn. \\n\\tpb\\tdouble precision  -- PB của công ty, mã chứng khoán, doanh nghiệp, tập đoàn. \\n)\\n\\nCreate table public.indicator_signal -- Tín hiệu kĩ thuật RSI, MACD, Vượt đỉnh 52 tuần, phá đáy 52 tuần của các mã chứng khoán, công ty trong khung thời gian: ngày ( \\n\\tsymbol_\\tvarchar(65535) distkey -- Mã chứng khoán, công ty, doanh nghiệp, tập đoàn, ví dụ: HPG, vic, vcb,... \\n\\tpe\\tdouble precision  -- PE của công ty, mã chứng khoán, doanh nghiệp, tập đoàn. \\n\\tpb\\tdouble precision  -- PB của công ty, mã chứng khoán, doanh nghiệp, tập đoàn. \\n)\\n\\n', 'question': 'Top 5 mã có pe, pb cao nhất', 'fields': ['ty_le_tang_truong_doanh_thu_5_y', 'doanh_thu_5_y_ago', 'ty_le_tang_truong_loi_nhuan_5_y', 'accumulated_val_1w', 'ty_le_tang_truong_eps_5_y', 'loi_nhuan_5_y_ago', 'eps_5_y_ago', 'pb', 'pb', 'symbol', 'symbol', 'symbol', 'sma_5', 'pe', 'pe', 'close_price']}\n",
      "Native query: Top 5 mã có p/e, p/b cao nhất\n",
      "*1.1*SQL: ```sql\n",
      "SELECT mack, pe, pb\n",
      "FROM public_market.fact_symbol_cstc_yearly\n",
      "WHERE nam = 2023\n",
      "ORDER BY pe DESC, pb DESC\n",
      "LIMIT 5\n",
      "```\n",
      "debug1:  \n",
      "SELECT mack, pe, pb\n",
      "FROM public_market.fact_symbol_cstc_yearly\n",
      "WHERE nam = 2023\n",
      "ORDER BY pe DESC, pb DESC\n",
      "LIMIT 5\n",
      "```\n",
      "debug2:  \n",
      "SELECT mack, pe, pb\n",
      "FROM public_market.fact_symbol_cstc_yearly\n",
      "WHERE nam = 2023\n",
      "ORDER BY pe DESC, pb DESC\n",
      "LIMIT 5\n",
      "\n",
      "debug3:  SELECT mack, pe, pb\n",
      "FROM public_market.fact_symbol_cstc_yearly\n",
      "WHERE nam = 2023\n",
      "ORDER BY pe DESC, pb DESC\n",
      "LIMIT 5\n",
      "debug4:  SELECT mack, pe, pb\n",
      "FROM public_market.fact_symbol_cstc_yearly\n",
      "WHERE nam = 2023\n",
      "ORDER BY pe DESC, pb DESC\n",
      "LIMIT 5;\n",
      "Where cluase 1 : nam = 2023\n",
      "Where cluase 2 : nam = 2023\n",
      "AND pb IS NOT NULL\n",
      "Where cluase 2 : nam = 2023\n",
      "AND pb IS NOT NULL\n",
      "AND pe IS NOT NULL\n",
      "New select: SELECT mack, pe, pb\n",
      "FROM public_market.fact_symbol_cstc_yearly\n",
      "WHERE nam = 2023\n",
      "ORDER BY pe DESC, pb DESC\n",
      "LIMIT 5;\n",
      "*1*SQL: SELECT mack, pe, pb\n",
      "FROM public_market.fact_symbol_cstc_yearly\n",
      "WHERE nam = 2023\n",
      "AND pb IS NOT NULL\n",
      "AND pe IS NOT NULL\n",
      "ORDER BY pe DESC, pb DESC\n",
      "LIMIT 5;\n",
      "Generated SQL:\n",
      "SELECT mack, pe, pb\n",
      "FROM public_market.fact_symbol_cstc_yearly\n",
      "WHERE nam = 2023\n",
      "AND pb IS NOT NULL\n",
      "AND pe IS NOT NULL\n",
      "ORDER BY pe DESC, pb DESC\n",
      "LIMIT 5;\n",
      "Query result:\n",
      "[{'mack': 'VIT', 'pe': Decimal('10851.701200476078'), 'pb': Decimal('1.6647775494855288')}, {'mack': 'LBM', 'pe': Decimal('6094.6881802302905'), 'pb': Decimal('1.650719889844645')}, {'mack': 'BTH', 'pe': Decimal('3532.852886983406'), 'pb': Decimal('1.3399190862064803')}, {'mack': 'PXA', 'pe': Decimal('2197.10819061183'), 'pb': Decimal('0.582015226673436')}, {'mack': 'VRC', 'pe': Decimal('2028.0339491169964'), 'pb': Decimal('0.41456797393729067')}]\n"
     ]
    }
   ],
   "source": [
    "df_result = await symbol_filter('Top 5 mã có pe, pb cao nhất', debug=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-30T16:12:17.315925Z",
     "start_time": "2024-06-30T16:12:14.535026Z"
    }
   },
   "id": "5097125c82d01d18",
   "execution_count": 157
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "  mack        pe    pb\n0  VIT  10,851.7  1.66\n1  LBM  6,094.69  1.65\n2  BTH  3,532.85  1.34\n3  PXA  2,197.11  0.58\n4  VRC  2,028.03  0.41",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mack</th>\n      <th>pe</th>\n      <th>pb</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>VIT</td>\n      <td>10,851.7</td>\n      <td>1.66</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>LBM</td>\n      <td>6,094.69</td>\n      <td>1.65</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>BTH</td>\n      <td>3,532.85</td>\n      <td>1.34</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>PXA</td>\n      <td>2,197.11</td>\n      <td>0.58</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>VRC</td>\n      <td>2,028.03</td>\n      <td>0.41</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_process = process_table(df_result)\n",
    "df_process"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-30T16:12:20.404249Z",
     "start_time": "2024-06-30T16:12:20.398873Z"
    }
   },
   "id": "b66c8755c3fa6676",
   "execution_count": 158
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-30T16:11:30.107553Z",
     "start_time": "2024-06-30T16:11:30.104830Z"
    }
   },
   "id": "e650d766ef194db0",
   "execution_count": 154
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
